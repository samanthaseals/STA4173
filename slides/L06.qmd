---
title: "ANOVA Assumptions, Kruskal-Wallis, and Posthoc Testing"
subtitle: "STA4173: Biostatistics"
execute:
  echo: true
  warning: false
  message: false
  error: true
format: 
  revealjs:
    theme: uwf
    self-contained: true
    slide-number: false
    footer: "[STA4173 - Biostatistics](https://samanthaseals.github.io/STA4173)"
    width: 1600
    height: 900
    df-print: paged
    html-math-method: katex
editor: source
---

## Introduction: ANOVA Assumptions

- We previously discussed testing three or more means using ANOVA.

- We also discussed that ANOVA is an extension of the two-sample *t*-test.

- Recall that the *t*-test has two assumptions:

    - Equal variance between groups.
    
    - Normal distribution.
    
- We will extend our knowledge of checking assumptions today.    

## ANOVA Assumptions: Definition

- We can represent ANOVA with the following model:
$$ y_{ij} = \mu + \tau_i + \varepsilon_{ij} $$

- where:

    - $y_{ij}$ is the $j^{\text{th}}$ observation in the $i^{\text{th}}$ group,
    - $\mu$ is the overall (grand) mean,
    - $\tau_i$ is the treatment effect for group $i$, and
    - $\varepsilon_{ij}$ is the error term for the $j^{\text{th}}$ observation in the $i^{\text{th}}$ group.
    
## ANOVA Assumptions: Definition

- We assume that the error term follows a normal distribution with mean 0 and a constant variance, $\sigma^2$. i.e.,
$$\varepsilon_{ij} \overset{\text{iid}}{\sim} N(0, \sigma^2)$$

- Very important note: **the assumption is on the error term** and NOT on the outcome!

- We will use the residual (the difference between the observed value and the predicted value) to assess assumptions:
$$ e_{ij} = y_{ij} - \hat{y}_{ij} $$

## ANOVA Assumptions: Graphical Assessment
    
- **Normality**: quantile-quantile plot

    - Should have points close to the 45$^\circ$ line
    - We will focus on the "center" portion of the plot
    
- **Variance**: scatterplot of the residuals against the predicted values

    - Should be "equal spread" between the groups
    - No "pattern"

## ANOVA Assumptions: Graphical Assessment

- Like with *t*-tests, we will assess these assumptions graphically.

- We will return to the `classpackage` package and use the `anova_check()` function.

```{r}
#| eval: false

library(classpackage) 
anova_check(m)
```

## ANOVA Assumptions: Graphical Assessment

- Recall the dental example from last week,

::: {.panel-tabset}

## Results

```{r}
#| echo: false
library(tidyverse)
strength <- c(15.4, 12.9, 17.2, 16.6, 19.3,
              17.2, 14.3, 17.6, 21.6, 17.5,
               5.5,  7.7, 12.2, 11.4, 16.4,
              11.0, 12.4, 13.5,  8.9,  8.1)
system <- c(rep("Cojet",5), rep("Silistor",5), rep("Cimara",5), rep("Ceramic",5))
data <- tibble(system, strength)
m <- aov(strength ~ system, data = data)
summary(m)
```

## Code

```{r}
#| eval: false
library(tidyverse)
strength <- c(15.4, 12.9, 17.2, 16.6, 19.3,
              17.2, 14.3, 17.6, 21.6, 17.5,
               5.5,  7.7, 12.2, 11.4, 16.4,
              11.0, 12.4, 13.5,  8.9,  8.1)
system <- c(rep("Cojet",5), rep("Silistor",5), rep("Cimara",5), rep("Ceramic",5))
data <- tibble(system, strength)
m <- aov(strength ~ system, data = data)
summary(m)
```

:::

## ANOVA Assumptions: Assessing Graphically

- Let's assess the assumptions graphically,

::: {.panel-tabset}

## Code

```{r}
#| eval: false
library(classpackage)
anova_check(m)
```

## Graph

<center>
```{r}
#| echo: false
library(classpackage)
anova_check(m)
```
</center>

:::

## ANOVA Assumptions: Test for Variance

- We can formally check the variance assumption with the Brown-Forsythe-Levine test.

    - This test transforms the data and then performs ANOVA!
    
- The test statistic is calculated as follows, $$ F_0 = \frac{\sum_{i=1}^k n_i (\bar{z}_i - \bar{z})^2/(k-1)}{\sum_{i=1}^k \sum_{j=1}^{n_j}(z_{ij}-\bar{z}_i)^2/(n-k) }, $$ where

    - $k$ is the number of groups,
    - $n_i$ is the sample size of group i,
    - $n = \sum_{i=1}^k n_i$, and
    - $z_{ij} = |y_{ij} - \text{median}(y_i)|$

## ANOVA Assumptions: Brown-Forsythe-Levine Test for Variance

- **Hypotheses**

    - $H_0: \ \sigma^2_1 = ... = \sigma^2_k$
    - $H_1:$ at least one $\sigma^2_i$ is different

- **Test Statistic**

    - $F_0$ (take from resulting ANOVA table)
    
- ***p*-Value**

    - $p = P[F_{\text{df}_{\text{Trt}}, \text{df}_{\text{E}}} \ge F_0]$
    
- **Rejection Region**

    - Reject if $p < \alpha$.
  
## ANOVA Assumptions: Test for Variance

- We will use the [`leveneTest()`](https://www.rdocumentation.org/packages/car/versions/3.1-0/topics/leveneTest) function from the [`car`](https://www.rdocumentation.org/packages/car/versions/3.1-0) package.

```{r, echo = TRUE, eval = FALSE}
leveneTest([model results])
```

## ANOVA Assumptions: Test for Variance

- Let's formally test the variance in the dental example,

```{r, message = FALSE, warning = FALSE}
library(car)
leveneTest(m)
```
## ANOVA Assumptions: Test for Variance

- **Hypotheses**

    - $H_0: \ \sigma^2_1 = \sigma^2_2 = \sigma^2_3 = \sigma^2_4$
    - $H_1:$ at least one $\sigma^2_i$ is different

- **Test Statistic and *p*-Value**

    - $F_0 = 0.734$
    - $p = 0.547$
    
- **Rejection Region**

    - Reject if $p < \alpha$; $\alpha=0.05$.
    
- **Conclusion/Interpretation**

    - Fail to reject $H_0$.
    - There is not sufficient evidence to suggest that the variances are different.
    - i.e., the variance assumption is not broken.

## Example: Penguins

- Recall the [Palmer Penguin](https://allisonhorst.github.io/palmerpenguins/) data in R.

- We determined that there is a difference in bill lengths between the three species,
```{r, echo = TRUE}
penguins <- palmerpenguins::penguins
m1 <- lm(bill_length_mm ~ species, data = penguins)
anova(m1)
```

- Let's now assess the assumptions.

## Example: Penguins

- First, the graphical assessment.

<center>
```{r}
anova_check(m1)
```
</center>

## Example: Penguins

- We can also formally test the variance,

```{r}
leveneTest(m1)
```

## Example: Penguins

- **Hypotheses**

    - $H_0: \ \sigma^2_1 = \sigma^2_2 = \sigma^2_3$
    - $H_1:$ at least one $\sigma^2_i$ is different

- **Test Statistic and *p*-Value**

    - $F_0 = 2.243$
    - $p = 0.108$
    
- **Rejection Region**

    - Reject if $p < \alpha$; $\alpha=0.05$.
    
- **Conclusion/Interpretation**

    - Fail to reject $H_0$.
    - There is not sufficient evidence to suggest that the variances are different.
    - i.e., the variance assumption is not broken.
    
## Introduction: Kruskal-Wallis

- We just discussed the ANOVA assumptions.

$$\varepsilon_{ij} \overset{\text{iid}}{\sim} N(0, \sigma^2)$$

- We also discussed how to assess the assumptions:

    - Graphically using the `anova_check()` function.
    
    - Confirming the variance assumption using the BFL.

- If we break an assumption, we will turn to the nonparametric alternative, the Kruskal-Wallis.

## Kruskal-Wallis Test

- If we break ANOVA assumptions, we should implement the nonparametric version, the Kruskal-Wallis.

- The Kruskal-Wallis test determines if $k$ independent samples come from populations with the same distribution. 

- Our new hypotheses are

    - $H_0:$ the distributions of the populations are identical
    - $H_1:$ the distributions of the populations are not identical
    
- Alternatively,

    - $H_0: M_1 = ... = M_k$
    - $H_1:$ at least one $M_i$ is different

## Kruskal-Wallis Test

- The test statistic is as follows: $$ \chi^2_0 = \frac{12}{n(n+1)} \sum_{i=1}^k \frac{R_i^2}{n_i} - 3(n+1), $$ where
    
    - $R_i$ is the sum of the ranks for group $i$,
    - $n_i$ is the sample size for group $i$,
    - $n = \sum_{i=1}^k n_i$ = total sample size, and
    - $k$ is the number of groups.

- $H$ follows a $\chi^2$ distribution with $k-1$ degrees of freedom.

## Kruskal-Wallis Test

**Hypotheses**

  - $H_0: \ M_1 =  ... = M_k$
  - $H_1:$ at least one $M_i$ is different
  
**Test Statistic**

  - $\chi^2_0 = \frac{12}{n(n+1)} \sum_{i=1}^k \frac{R_i^2}{n_i} - 3(n+1)$ 
  
***p*-Value**

  - $p = P[\chi^2_{k-1} \ge \chi^2_0]$

**Rejection Region**

  - Reject $H_0$ if $p < \alpha$
  
## Kruskal-Wallis Test

- We will use the [`kruskal.test()`](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/kruskal.test) function to perform the Kruskal-Wallis test.

```{r, echo = TRUE, eval = FALSE}
kruskal.test([outcome variable] ~ [grouping variable], 
             data = [dataset])
```

## Example: HDL
    
-A family doctor wants to determine if the distributions of HDL cholesterol in males for the age groups 20 to 29 years, 40 to 49 years, and 60 to 69 years old are different. 

- He obtains a simple random sample of 12 individuals from each age group and determines their HDL cholesterol. 

- Do the data indicate the distributions vary depending on age? Use the $\alpha = 0.05$ level of significance.

```{r, warning = FALSE, message = FALSE}
library(tidyverse)
HDL <- c(54, 43, 38, 30, 61, 53, 35, 34, 39, 46, 50, 35,
         61, 41, 44, 47, 33, 29, 59, 35, 34, 74, 50, 65,
         44, 65, 62, 53, 51, 49, 49, 42, 35, 44, 37, 38)
age <- c(rep("20 to 29", 12), rep("40 to 49", 12), rep("60 to 69", 12))
data <- tibble(age, HDL)
```

## Example: HDL

- Let's first assess the ANOVA assumptions:

<center>
```{r, echo = FALSE}
#| echo: false
anova_check(lm(HDL ~ age, data = data))
```
</center>

## Example: HDL

- Running the test in R,

```{r}
kruskal.test(HDL ~ age, data = data)
```

## Example: HDL 

**Hypotheses**

  - $H_0: \ M_1 = M_2 = M_3$
  - $H_1:$ at least one $M_i$ is different
  
**Test Statistic and *p*-Value**

  - $\chi_0^2 = 1.012$ 
  - $p = 0.602$

**Rejection Region**

  - Reject $H_0$ if $p < \alpha$
  
**Conclusion/Interpretation**

  - Fail to reject $H_0$. There is not sufficient evidence to suggest that there is a difference between the three groups.

## Kruskal-Wallis: Posthoc Testing

- We can also perform posthoc testing in the Kruskal-Wallis setting.

- The set up is just like Tukey's -- we can perform all pairwise comparisons and control for the Type I error rate.

- Instead of using $|\bar{y}_i - \bar{y}_j|$, we will use $|\bar{R}_i - \bar{R}_j|$, where $\bar{R}_i$ is the average rank of group $i$.

- The comparison we are making:

    - We declare $M_i \ne M_j$ if $|\bar{R}_i - \bar{R}_j| \ge KW$, where
    $$ KW = \frac{q_{\alpha}(k, \infty)}{\sqrt{2}} \sqrt{\frac{n(n+1)}{12} \left( \frac{1}{n_i} + \frac{1}{n_j} \right)} $$ and $q_{\alpha}(k, \infty)$ is the critical value from the Studentized range distribution.

## Kruskal-Wallis: Posthoc Testing

- We will use the [`kruskalmc()`](https://www.rdocumentation.org/packages/pgirmess/versions/2.0.0/topics/kruskalmc) function from the [`pgirmess` package](https://www.rdocumentation.org/packages/pgirmess/versions/2.0.0) to perform the Kruskal-Wallis post-hoc test.

```{r, echo = TRUE, eval = FALSE}
kruskalmc([outcome variable] ~ [grouping variable], 
          data = [dataset])
```

## Example: HDL

::: {.panel-tabset}

## Set Up

- Revisiting our example,

    - Note that if we were doing this "for real" we would not do the posthoc test since we did not see a difference between the three groups.
    
    - We are doing it here for demonstration purposes.

## Code 

```{r}
#| eval: false
library(pgirmess) 
kruskalmc(HDL ~ age, data = data)
```

## Results 

```{r}
#| echo: false
library(pgirmess) 
kruskalmc(HDL ~ age, data = data)
```

- Thus, none of the groups are different from one another.

:::

## Example: Penguins

- Recall the [Palmer Penguin](https://allisonhorst.github.io/palmerpenguins/) data in R.

::: {.panel-tabset}

## Box Plot

<center>
```{r}
#| echo: false
penguins %>% 
  ggplot(aes(y = bill_length_mm, x = species, fill = species)) +
  geom_boxplot() +
  labs(y = "Bill Length (mm)",
       x = "Species") +
  theme_bw() +
  theme(legend.position = "none")
```
</center>

## Kruskal-Wallis: Global

- Let's check the overall difference in bill lengths using the Kruskal-Wallis.

```{r}
penguins <- palmerpenguins::penguins
kruskal.test(bill_length_mm ~ species, data = penguins)
```

## Kruskal-Wallis: Pairwise

- Let's check the pairwise differences in bill lengths using the Kruskal-Wallis approach.

```{r}
library(pgirmess) 
kruskalmc(bill_length_mm ~ species, data = penguins)
```

- Adelies are different from both chinstraps and gentoos.

- Chinstraps and gentoos are not different.

:::









