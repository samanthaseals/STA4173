---
title: "Posthoc Testing in One-Way ANOVA"
subtitle: "STA4173: Biostatistics"
execute:
  echo: true
format: 
  revealjs:
    theme: uwf
    self-contained: true
    slide-number: false
    footer: "[STA4173 - Biostatistics](https://samanthaseals.github.io/STA4173)"
    width: 1600
    height: 900
    df-print: paged
    html-math-method: katex
editor: source
---

## Introduction

- In the last lecture, we introduced ANOVA. Recall the hypotheses,

    - $H_0: \mu_1 = \mu_2 = ... = \mu_k$
    - $H_1:$ at least one $\mu_i$ is different
    
- The $F$ test does not tell us *which* mean is different... only that a difference exists.

- In theory, we could perform repeated $t$ tests to determine pairwise differences.

    - Recall that ANOVA is an extension of the $t$ test... or that the $t$ test is a special case of ANOVA.
    
    - However, this will increase the Type I error rate ($\alpha$).

## Introduction

- Recall that the Type I error rate, $\alpha$, is the probability of *incorrectly* rejecting $H_0$.

    - i.e., we are saying there is a difference between the means when there is actually *not* a difference.
    
- Suppose we are comparing 5 groups.

    - This is 10 pairwise comparisons!! 
        
        - 1-2, 1-3, 1-4, 1-5, 2-3, 2-4, 2-5, 3-4, 3-5, 4-5
        
    - If we perform repeated $t$ tests under $\alpha=0.05$, we are inflating the Type I error to 0.40! ðŸ˜µ

## Introduction

- When performing posthoc comparisons, we can choose one of two paths:

    - Control the Type I (familywise) error rate.
    - Do not control the Type I error rate.
    
- Note that controlling the Type I error rate is more conservative than when we do not control it.

    - "Conservative" = more difficult to reject.
    
- Generally, statisticians:

    - *do not* control the Type I error rate if examining the results of pilot/preliminary studies that are exploring for general relationships.
    
    - *do* control the Type I error rate if examining the results of confirmatory studies and are attempting to confirm relationships observed in pilot/preliminary studies.
    
## Introduction

- The posthoc tests we will learn:

    - Tukey's test
    
        - Performs all pairwise tests and controls the Type I error rate
        
    - Fisher's least significant difference 
    
        - Performs all pairwise tests but does not control the Type I error rate
        
    - Dunnett's test
    
        - Compares each group to a control group and controls the Type I error rate
        
- **Caution**: we should *only* perform posthoc tests if we have determined that a general difference exists!

    - i.e., we rejected when looking at the $F$ test in ANOVA
    
## Example

- Recall the dental example from last lecture,

```{r, echo = FALSE, warning = FALSE, message = FALSE}
library(tidyverse)
```

```{r}
strength <- c(15.4, 12.9, 17.2, 16.6, 19.3,
              17.2, 14.3, 17.6, 21.6, 17.5,
               5.5,  7.7, 12.2, 11.4, 16.4,
              11.0, 12.4, 13.5,  8.9,  8.1)
system <- c(rep("Cojet",5), rep("Silistor",5), rep("Cimara",5), rep("Ceramic",5))
data <- tibble(system, strength)
m <- aov(strength ~ system, data = data)
summary(m)
```

- Are we justified in posthoc testing? (Recall: $\alpha=0.01$).

## Tukey's Test

- Tukey's test allows us to do all pairwise comparisons while controlling $\alpha$.

- The underlying idea of the comparison:

    - We declare $\mu_i \ne \mu_j$ if $|\bar{y}_i - \bar{y}_j| \ge W$, where $$ W = \frac{q_{\alpha}(k, \text{df}_{\text{E}})}{\sqrt{2}} \sqrt{\text{MSE} \left( \frac{1}{n_i} + \frac{1}{n_j} \right)} $$
    
        - $q_{\alpha}(k, \text{df}_{\text{E}})$ is the critical value from the Studentized range distribution.

## Tukey's Test

- We will use the [`TukeyHSD()`](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/TukeyHSD) function.

    - Note that this requires us to have created our model using the `aov()` function.

```{r, eval = FALSE}
m <- aov([continuous variable] ~ [grouping variable], data = [dataset name])
TukeyHSD(m)$[grouping variable]
```

## Tukey's Test

- Let's apply Tukey's to the dental data.

```{r}
m <- aov(strength ~ system, data = data)
TukeyHSD(m)$system
```

- Which are significantly different at the $\alpha=0.01$ level?

## Tukey's Test

- Let's apply Tukey's to the dental data.

```{r}
m <- aov(strength ~ system, data = data)
TukeyHSD(m, conf.level = 0.99)$system
```

- Which are significantly different at the $\alpha=0.01$ level?

    - <font color="#db0b9d">Silistor-Cimara</font>

## Fisher's Test

- Fisher's allows us to test all pairwise comparisons but \textbf{does not} control the $\alpha$.

- The underlying idea of the comparison:

    - We declare $\mu_i \ne \mu_j$ if $|\bar{y}_i - \bar{y}_j| \ge \text{LSD}$, where $$ \text{LSD} = t_{1-\alpha/2, \text{df}_\text{E}} \sqrt{\text{MSE} \left( \frac{1}{n_i} + \frac{1}{n_j} \right)} $$

## Fisher's Test

- We will use the [`LSD.test()`](https://www.rdocumentation.org/packages/agricolae/versions/1.3-5/topics/LSD.test) function from the [`agricolae`](https://www.rdocumentation.org/packages/agricolae/versions/1.3-5) package.

    - Note that, like Tukey's, this requires us to have created our model using the `aov()` function.

```{r, eval = FALSE}
library(agricolae)
results <- summary(m)
(LSD.test([dataset]$[continuous], # continuous outcome
          [dataset]$[grouping], # grouping variable
          results[[1]]$Df[2], # df_E
          results[[1]]$`Mean Sq`[2], # MSE
          alpha = [alpha level]) # can omit if alpha = 0.05
  )[5] # limit to only the pairwise comparison results
```

## Fisher's Test

- Let's apply Fisher's to the dental data.

```{r}
library(agricolae)
results <- summary(m)
LSD.test(data$strength, 
         data$system, 
         results[[1]]$Df[2], 
         results[[1]]$`Mean Sq`[2],
         alpha = 0.01)[5]
```

- Which are significantly different at the $\alpha=0.01$ level?

## Fisher's Test

- Let's apply Fisher's to the dental data.

```{r}
library(agricolae)
results <- summary(m)
LSD.test(data$strength, 
         data$system, 
         results[[1]]$Df[2], 
         results[[1]]$`Mean Sq`[2],
         alpha = 0.01)[5]
```

- Which are significantly different at the $\alpha=0.01$ level?

    - <font color="#db0b9d">Silistor-Ceramic</font>
    - <font color="#db0b9d">Silistor-Cimara</font>
    - <font color="#db0b9d">Cojet-Ceramic</font>
    - <font color="#db0b9d">Cojet-Cimara</font>    

## Dunnett's Test 

- Dunnett's test allows us to do all pairwise comparisons against only the control, while controlling $\alpha$.

    - This has fewer comparisons than Tukey's because we are not comparing non-control groups to one another.
    
    - i.e., we are sharing the $\alpha$ between fewer comparisons now, which is preferred if we are not interested in the comparisons between non-control groups.

- The underlying idea of the comparison:

    - We declare $\mu_i \ne \mu_j$ if $|\bar{y}_i - \bar{y}_j| \ge D$, where $$ D = d_{\alpha}(k-1, \text{df}_{\text{E}}) \sqrt{\text{MSE} \left( \frac{1}{n_i} + \frac{1}{n_c} \right)}, $$
        
        - $d_{\alpha}(k-1, \text{df}_{\text{E}})$ is the critical value from Dunnett's table.

## Dunnett's Test

- We will use the [`DunnettTest()`](https://www.rdocumentation.org/packages/DescTools/versions/0.99.32/topics/DunnettTest) function from the DescTools package to perform Dunnett's test.

```{r, echo = TRUE, eval = FALSE}
library(DescTools)
DunnettTest(x=[dataset]$[continuous variable], 
            g=[dataset]$[grouping variable], 
            control = "[name of control group]")
```

- The *p*-values are adjusted, so you can directly compare them to the specified $\alpha$.

## Dunnett's Test

- Let's apply Dunnett's to the dental data.

    - We will treat "Ceramic" as the control group.

```{r, message = FALSE, mwarning = FALSE}
library(DescTools)
DunnettTest(x=data$strength, 
            g=data$system, 
            control = "Ceramic")
```

- Which are significantly different at the $\alpha=0.01$ level?

## Dunnett's Test

- Let's apply Dunnett's to the dental data.

    - We will treat "Ceramic" as the control group.

```{r, message = FALSE, mwarning = FALSE}
library(DescTools)
DunnettTest(x=data$strength, 
            g=data$system, 
            control = "Ceramic")
```

- Which are significantly different at the $\alpha=0.01$ level?

    - <font color="#db0b9d">Silistor-Ceramic</font>

## Example - Penguins

- Recall the [Palmer Penguin](https://allisonhorst.github.io/palmerpenguins/) data in R.

```{r, echo = TRUE}
penguins <- palmerpenguins::penguins
m1 <- aov(bill_length_mm ~ species, data = penguins)
summary(m1)
```

## Example - Penguins

<center>
```{r, echo = FALSE}
penguins %>% ggplot(aes(y = bill_length_mm, x = species, fill = species)) +
  geom_boxplot() +
  theme_bw()
```
</center>

## Example - Penguins

- Let's use Tukey's test to determine what differences exist between the species. 

```{r}
TukeyHSD(m1)$species
```

- Which species are significantly different at the $\alpha=0.05$ level?

## Example - Penguins

- Let's use Tukey's test to determine what differences exist between the species. 

```{r}
TukeyHSD(m1)$species
```

- Which species are significantly different at the $\alpha=0.05$ level?

    - <font color="#db0b9d">Chinstrap-Adelie</font>
    - <font color="#db0b9d">Gentoo-Adelie</font>
    - <font color="#db0b9d">Gentoo-Chinstrap</font>




























































































