---
title: "Paired *t*-Test (Dependent Means)"
subtitle: "STA4173: Biostatistics"
execute:
  echo: true
format: 
  revealjs:
    theme: uwf
    self-contained: true
    slide-number: false
    footer: "[STA4173 - Biostatistics](https://samanthaseals.github.io/STA4173)"
    width: 1600
    height: 900
    df-print: paged
    html-math-method: katex
editor: source
---

## Independent vs. Dependent Data

-   **Independent**: An individual selected for one sample does not dictate which individual is to be in a second sample.

    -   e.g., there are two sections of STA4173; sampling from each would be independent samples

        -   there is not a way for us to link the individuals in the samples

-   **Dependent**: An individual selected to be in one sample is used to determine the individual in the second sample.

    -   e.g., sampling from one section of STA4173 and examining project grades over time would be dependent samples

        -   we can link on student ID

## Estimating $\mu_1-\mu_2$

-   We are now interested in comparing two **dependent** groups.

-   We assume that the two groups come from the same population and are going to examine the difference,

$$
d = y_{i, 1} - y_{i, 2}
$$

-   After drawing samples, we have the following,

    -   $\bar{d}$ estimates $\mu_d$,

    -   $s^2_d$ estimates $\sigma^2_d$, and

    -   $n$ is the sample size.

## Confidence Interval for $\mu_d$

-   $\mathbf{(1-\boldsymbol\alpha)100\%}$ CI for the difference between two population means, $\mathbf{\boldsymbol\mu_d}$:

$$ \bar{d} \pm t_{\alpha/2} \frac{s_d}{\sqrt{n}} $$

-   where $t_{\alpha/2}$ has $n-1$ degrees of freedom.

-   To construct this interval, we require either:

    -   the differences to be normally distributed or
    -   the sample size is sufficiently large ($n \ge 30$)

## Confidence Interval for $\mu_d$

-   We will use the [`t.test()`](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/t.test) function to find the CI,

```{r, echo = TRUE, eval = FALSE}
t.test([dataset]$[var1], [dataset]$[var2], 
       paired = TRUE, 
       conf.level = [confidence level])
```

## Confidence Interval for $\mu_d$

-   Insurance adjusters are concerned about the high estimates they are receiving for auto repairs from garage I compared to garage II.

-   15 cars were taken to both garages for separate estimates of repair costs.

```{r, echo = FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
```

```{r}
g1 <- c(17.6, 20.2, 19.5, 11.3, 13.0, 
        16.3, 15.3, 16.2, 12.2, 14.8, 
        21.3, 22.1, 16.9, 17.6, 18.4)
g2 <- c(17.3, 19.1, 18.4, 11.5, 12.7, 
        15.8, 14.9, 15.3, 12.0, 14.2, 
        21.0, 21.0, 16.1, 16.7, 17.5)
garage <- tibble(g1, g2)
```

-   Construct the 95% confidence interval for the average difference between the two garages.

## Confidence Interval for $\mu_d$

```{r}
t.test(garage$g1, garage$g2, 
       paired = TRUE, 
       conf.level = 0.95)
```

-   The 95% CI for $\mu_d$, where $d = x_{\text{I}} - x_{\text{II}}$ is $(0.39, 0.83)$.

## Confidence Interval for $\mu_d$

-   From the problem statement:

    -   *Insurance adjusters are concerned about the high estimates they are receiving for auto repairs from garage I compared to garage II.*

-   Our CI is (0.39, 0.83) -- can we say that estimates from garage I are higher than those from garage II?

## Confidence Interval for $\mu_d$

-   From the problem statement:

    -   *Insurance adjusters are concerned about the high estimates they are receiving for auto repairs from garage I compared to garage II.*

-   Our CI is (0.39, 0.83) -- can we say that estimates from garage I are higher than those from garage II?

    -   <font color="#db0b9d">Yes; the CI is entirely above 0 and the subtraction order was garage I - garage II.</font>

## Paired *t*-Test

-   **Hypothesis Test for Two Dependent Means**:

<center><img src="images/L04a.png"/></center>

## Paired *t*-Test

-   We again use the [`t.test()`](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/t.test) function to perform the test,

```{r, echo = TRUE, eval = FALSE}
t.test([dataset]$[var1], [dataset]$[var2], 
       paired = TRUE, 
       mu = [hypothesized difference],
       alternative = "[alternative]")
```

-   Important!!

    -   R is going to subtract in the order that we plugged var1 and var2 into the `t.test()`.

## Paired *t*-Test

-   Let's now formally determine if garage I's estimates are higher than garage II's. Test at the $\alpha=0.05$ level.

```{r}
t.test(garage$g1, garage$g2,
       paired = TRUE,
       mu = 0,
       alternative = "greater")
```

## Paired *t*-Test

-   **Hypotheses**

    -   $H_0: \ \mu_{\text{I}} \le \mu_{\text{II}}$ OR $\mu_{d} \le 0$, where $\mu_d = \mu_{\text{I}} - \mu_{\text{II}}$
    -   $H_1: \ \mu_{\text{I}} > \mu_{\text{II}}$ OR $\mu_{d} > 0$

-   **Test Statistic and *p*-Value**

    -   $t_0 = 6.023$
    -   $p < 0.001$

-   **Rejection Region**

    -   Reject $H_0$ if $p < \alpha$; $\alpha = 0.05$.

-   **Conclusion/Interpretation**

    -   Reject $H_0$.

    -   There is sufficient evidence to suggest the estimates at garage I are higher than that of garage II.

## Example

-   Professor Neill measured the time (in seconds) required to catch a falling meter stick for 12 randomly selected students' dominant and nondominant hands.

-   A coin flip is used to determine whether reaction time is measured using the dominant or nondominant hand first.

```{r}
dom <- c(0.177, 0.210, 0.186, 0.189, 0.198, 0.194, 
         0.160, 0.163, 0.166, 0.152, 0.190, 0.172)
non <- c(0.179, 0.202, 0.208, 0.184, 0.215, 0.193, 
         0.194, 0.160, 0.209, 0.164, 0.210, 0.197)
students <- tibble(dom, non)
```

-   Professor Neill wants to know if the reaction time in an individual's dominant hand is equal to the reaction time in their nondominant hand.

    -   First, find the 99% CI for the difference in reaction times.

    -   Then, formally test to determine if there is a difference; test at the $\alpha=0.01$ level.

## Example

-   Let's first describe the data.

-   Our first step will be to find the difference so that we can look at $\bar{d}$ and $s_d$.

    -   *Is the reaction time in an individual's dominant hand equal to the reaction time in their nondominant hand?*

```{r}
students <- students %>% 
  mutate(d = dom - non) # create the difference

head(students, n = 3) # view the dataset on the slide
```

## Example

- We would like to know what the distribution looks like, so let's create a box plot,

<center>
```{r}
students %>% ggplot(aes()) +
  geom_boxplot(aes(y = dom, x = "Dominant")) +
  geom_boxplot(aes(y = non, x = "Non-Dominant")) +
  labs(x = "",
       y = "Reaction Time") +
  theme_bw() 
```
</center>

## Example

- We would like to know what the distribution looks like, so let's create a box plot,

<center>
```{r}
students %>% ggplot(aes(y = d)) +
  geom_boxplot() +
  labs(x = "",
       y = "Difference \n(Dominant - Non-dominant)") +
  theme_bw() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank())
```
</center>

## Example

-   To describe, we will look at means and standard deviations:

```{r}
students %>% summarize(mean(dom), sd(dom), # summary of dominant hand
                       mean(non), sd(non), # summary of non-dominant hand
                       mean(d), sd(d)) # summary of difference
```

|                                      | Mean (Std. Dev) |
|--------------------------------------|:---------------:|
| Dominant Hand                        |  0.180 (0.018)  |
| Non-dominant Hand                    |  0.193 (0.018)  |
| Difference (Dominant - Non-dominant) | -0.013 (0.016)  |

## Example

- Let's now find the 99% CI for the difference in reaction time ($\mu_d$).

```{r}
t.test(students$dom, students$non, 
       paired = TRUE, 
       conf.level = 0.99)
```

- The 99% CI for $\mu_d$, where $d = x_{\text{dominant}} - x_{\text{non-dominant}}$ is $(-0.028, 0.002)$.

## Example

- The 99% CI for $\mu_d$, where $d = x_{\text{dominant}} - x_{\text{non-dominant}}$ is $(-0.028, 0.002)$.

    - Can we say that there is a difference in the reaction times?
    
## Example

- The 99% CI for $\mu_d$, where $d = x_{\text{dominant}} - x_{\text{non-dominant}}$ is $(-0.028, 0.002)$.

    - Can we say that there is a difference in the reaction times?
    
        - <font color="#db0b9d">No, 0 is included in the interval</font>
        
## Example

-   Let's now formally determine there is a difference between the reaction of dominant and non-dominant hands.

```{r}
t.test(students$dom, students$non, 
       paired = TRUE, 
       mu = 0,
       alternative = "two")
```

## Example

-   **Hypotheses**

    -   $H_0: \ \mu_{\text{dominant}} = \mu_{\text{non-dominant}}$ OR $\mu_{d} = 0$, where $\mu_d = \mu_{\text{dominant}} - \mu_{\text{non-dominant}}$
    -   $H_1: \ \mu_{\text{dominant}} \ne \mu_{\text{non-dominant}}$ OR $\mu_{d} \ne 0$

-   **Test Statistic and *p*-Value**

    -   $t_0 = -2.2776$
    -   $p = 0.018$

-   **Rejection Region**

    -   Reject $H_0$ if $p < \alpha$; $\alpha = 0.01$.

-   **Conclusion/Interpretation**

    -   Fail to reject $H_0$.

    -   There is not sufficient evidence to suggest that there is a difference in reaction times between dominant and non-dominant hands.
    
    
